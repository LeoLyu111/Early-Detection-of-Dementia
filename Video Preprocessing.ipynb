{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e539526b",
   "metadata": {},
   "source": [
    "# Video Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f3007f",
   "metadata": {},
   "source": [
    "This documentation is used to process video data into images and text to do the prediction that whether the person in video has dementia.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ff1715",
   "metadata": {},
   "source": [
    "## Part 1: Video to image\n",
    "This part is to cut the test video into several pictures to do image prediction to test whether the person in video has dementia. The test process is in Documentation 3.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "645fbc8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /Users/lyuliangyi/opt/anaconda3/lib/python3.8/site-packages (4.6.0.66)\r\n",
      "Requirement already satisfied: numpy>=1.17.3 in /Users/lyuliangyi/opt/anaconda3/lib/python3.8/site-packages (from opencv-python) (1.22.3)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3328ad40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import sys\n",
    "from moviepy.editor import VideoFileClip\n",
    "import xlwt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f0cb44",
   "metadata": {},
   "source": [
    "### For dementia test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fab752f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vc_dem = cv2.VideoCapture('test_dementia.mp4')  # read video file\n",
    "n = 1  # count number\n",
    "\n",
    "if vc_dem.isOpened():  # judge whether it can open \n",
    "    rval_dem, frame_dem = vc_dem.read()\n",
    "else:\n",
    "    rval_dem = False\n",
    "\n",
    "timeF = 100  # take picture every 'timeF' Frames\n",
    "\n",
    "i = 0\n",
    "while rval_dem:  # Loop to read video frames\n",
    "    rval_dem, frame_dem = vc_dem.read()\n",
    "    if (n % timeF == 0):  # Store operations every timeF frame\n",
    "        i += 1\n",
    "        rows, cols, channel = frame_dem.shape  # Rotate picture if needed\n",
    "        M = cv2.getRotationMatrix2D((cols/2, rows/2), 180, 1)\n",
    "        frame_dem = cv2.warpAffine(frame_dem, M, (cols, rows))\n",
    "        cv2.imwrite('/Users/lyuliangyi/Desktop/STAT8021/STAT8021 Group 2(1)/Documentation 2. Video Preprocessing/figure/test_dementia/image_dem{}.jpg'.format(i), frame_dem)  # 存储为图像\n",
    "    n = n + 1\n",
    "    cv2.waitKey(1)\n",
    "vc_dem.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61479fbe",
   "metadata": {},
   "source": [
    "### For normal test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d53e94ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "vc_nor = cv2.VideoCapture('test_normal.mp4')  # read video file\n",
    "n = 1  # count number\n",
    "\n",
    "if vc_nor.isOpened():  # judge whether it can open \n",
    "    rval_nor, frame_nor = vc_nor.read()\n",
    "else:\n",
    "    rval_nor = False\n",
    "\n",
    "timeF = 100  # take picture every 'timeF' Frames\n",
    "\n",
    "i = 0\n",
    "while rval_nor:  # Loop to read video frames\n",
    "    rval_nor, frame_nor = vc_nor.read()\n",
    "    if (n % timeF == 0):  # Store operations every timeF frame\n",
    "        i += 1\n",
    "        rows, cols, channel = frame_nor.shape  # Rotate picture if needed\n",
    "        M = cv2.getRotationMatrix2D((cols/2, rows/2), 180, 1)\n",
    "        frame_nor = cv2.warpAffine(frame_nor, M, (cols, rows))\n",
    "        cv2.imwrite('/Users/lyuliangyi/Desktop/STAT8021/STAT8021 Group 2(1)/Documentation 2. Video Preprocessing/figure/test_normal/image_nor{}.jpg'.format(i), frame_nor)  # 存储为图像\n",
    "    n = n + 1\n",
    "    cv2.waitKey(1)\n",
    "vc_nor.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134a3223",
   "metadata": {},
   "source": [
    "### For dementia video collected from internet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "410fb559",
   "metadata": {},
   "outputs": [],
   "source": [
    "vc_dementia = cv2.VideoCapture('dementia.mp4')  # read video file\n",
    "n = 1  # count number\n",
    "\n",
    "if vc_dementia.isOpened():  # judge whether it can open \n",
    "    rval_dementia, frame_dementia = vc_dementia.read()\n",
    "else:\n",
    "    rval_dementia = False\n",
    "\n",
    "timeF = 100  # take picture every 'timeF' Frames\n",
    "\n",
    "i = 0\n",
    "while rval_dementia:  # Loop to read video frames\n",
    "    rval_dementia, frame_dementia = vc_dementia.read()\n",
    "    if (n % timeF == 0):  # Store operations every timeF frame\n",
    "        i += 1\n",
    "        rows, cols, channel = frame_dementia.shape  # Rotate picture if needed\n",
    "        M = cv2.getRotationMatrix2D((cols/2, rows/2), 180, 1)\n",
    "        frame_dementia = cv2.warpAffine(frame_dementia, M, (cols, rows))\n",
    "        cv2.imwrite('/Users/lyuliangyi/Desktop/STAT8021/STAT8021 Group 2(1)/Documentation 2. Video Preprocessing/figure/dementia/image_dementia{}.jpg'.format(i), frame_dementia)  # 存储为图像\n",
    "    n = n + 1\n",
    "    cv2.waitKey(1)\n",
    "vc_dementia.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0759dbe",
   "metadata": {},
   "source": [
    "## Part 2: Video to audio\n",
    "This part is to convert the sound from the video to an audio file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c9e3668",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in test_dementia.wav\n",
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in test_normal.wav\n",
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "def convert_video_to_audio_moviepy(video_file, output_ext=\"wav\"):\n",
    "    \n",
    "    \"\"\"Converts video to audio using MoviePy library\n",
    "    that uses `ffmpeg` under the hood\"\"\"\n",
    "    \n",
    "    filename, ext = os.path.splitext(video_file)\n",
    "    clip = VideoFileClip(video_file)\n",
    "    clip.audio.write_audiofile(f\"{filename}.{output_ext}\")\n",
    "\n",
    "# for dementia test\n",
    "if __name__ == \"__main__\":\n",
    "    vf_dem = 'test_dementia.mp4'\n",
    "    convert_video_to_audio_moviepy(vf_dem)\n",
    "    \n",
    "# for normal test \n",
    "if __name__ == \"__main__\":\n",
    "    vf_nor = 'test_normal.mp4'\n",
    "    convert_video_to_audio_moviepy(vf_nor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56c3431",
   "metadata": {},
   "source": [
    "## Part 3: Audio to text\n",
    "This part we do speech recognition to convert the audio to text. We will use the text we got form this part do text prediction to test whether the person in video has dementia in Documentation 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2271a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Pydub in /Users/lyuliangyi/opt/anaconda3/lib/python3.8/site-packages (0.25.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install Pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0be0295d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr \n",
    "import os \n",
    "from pydub import AudioSegment\n",
    "from pydub.silence import split_on_silence\n",
    "\n",
    "# create a speech recognition object\n",
    "r = sr.Recognizer()\n",
    "\n",
    "# a function that splits the audio file into chunks\n",
    "# and applies speech recognition\n",
    "\n",
    "def get_large_audio_transcription(path):\n",
    "    \"\"\"\n",
    "    Splitting the large audio file into chunks\n",
    "    and apply speech recognition on each of these chunks\n",
    "    \"\"\"\n",
    "    # open the audio file using pydub\n",
    "    sound = AudioSegment.from_wav(path)  \n",
    "    # split audio sound where silence is 700 miliseconds or more and get chunks\n",
    "    chunks = split_on_silence(sound,\n",
    "        # experiment with this value for your target audio file\n",
    "        min_silence_len = 500,\n",
    "        # adjust this per requirement\n",
    "        silence_thresh = sound.dBFS-14,\n",
    "        # keep the silence for 1 second, adjustable as well\n",
    "        keep_silence=500,\n",
    "    )\n",
    "    folder_name = \"audio-chunks\"\n",
    "    # create a directory to store the audio chunks\n",
    "    if not os.path.isdir(folder_name):\n",
    "        os.mkdir(folder_name)\n",
    "    whole_text = \"\"\n",
    "    # process each chunk \n",
    "    for i, audio_chunk in enumerate(chunks, start=1):\n",
    "        # export audio chunk and save it in\n",
    "        # the `folder_name` directory.\n",
    "        chunk_filename = os.path.join(folder_name, f\"chunk{i}.wav\")\n",
    "        audio_chunk.export(chunk_filename, format=\"wav\")\n",
    "        # recognize the chunk\n",
    "        with sr.AudioFile(chunk_filename) as source:\n",
    "            audio_listened = r.record(source)\n",
    "            # try converting it to text\n",
    "            try:\n",
    "                text = r.recognize_google(audio_listened)\n",
    "            except sr.UnknownValueError as e:\n",
    "                print(\"Error:\", str(e))\n",
    "            else:\n",
    "                text = f\"{text.capitalize()}. \"\n",
    "                print(chunk_filename, \":\", text)\n",
    "                whole_text += text\n",
    "    # return the text for all chunks detected\n",
    "    return whole_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142c9304",
   "metadata": {},
   "source": [
    "### For dementia test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "37d5f196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "audio-chunks/chunk1.wav : The poem mother's doing dishes. \n",
      "audio-chunks/chunk2.wav : There's a boy on the stew. \n",
      "audio-chunks/chunk3.wav : Cookie jar in a go down below. \n",
      "Error: \n",
      "audio-chunks/chunk5.wav : The all you wanted to know. \n",
      "audio-chunks/chunk6.wav : Cookie jar. \n",
      "audio-chunks/chunk7.wav : The little boy standing on a stool and is ready to go over. \n",
      "audio-chunks/chunk8.wav : The little girl standing there the mother's the sink doing dishes. \n",
      "audio-chunks/chunk9.wav : What does overflowing that's about it. \n",
      "\n",
      "Dementia test text: The poem mother's doing dishes. There's a boy on the stew. Cookie jar in a go down below. The all you wanted to know. Cookie jar. The little boy standing on a stool and is ready to go over. The little girl standing there the mother's the sink doing dishes. What does overflowing that's about it. \n"
     ]
    }
   ],
   "source": [
    "path_dem = 'test_dementia.wav'\n",
    "text_output_dem = get_large_audio_transcription(path_dem)\n",
    "print(\"\\nDementia test text:\", text_output_dem)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0434be8",
   "metadata": {},
   "source": [
    "### For normal test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c294aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "audio-chunks/chunk1.wav : The three persons in the kitchen. \n",
      "audio-chunks/chunk2.wav : A mother and her two kids. \n",
      "audio-chunks/chunk3.wav : The mother is watching fishes for the water coming out of the sink. \n",
      "audio-chunks/chunk4.wav : The boy standing on a stool to take cookies from the jar in the cupboard. \n",
      "audio-chunks/chunk5.wav : But they still is unsteady and he seems to favour. \n",
      "audio-chunks/chunk6.wav : The girl is raising her hand out. \n",
      "audio-chunks/chunk7.wav : Nsr finger on hurley. \n",
      "audio-chunks/chunk8.wav : Send to ask the boy not to make any noise. \n",
      "\n",
      "Normal test text: The three persons in the kitchen. A mother and her two kids. The mother is watching fishes for the water coming out of the sink. The boy standing on a stool to take cookies from the jar in the cupboard. But they still is unsteady and he seems to favour. The girl is raising her hand out. Nsr finger on hurley. Send to ask the boy not to make any noise. \n"
     ]
    }
   ],
   "source": [
    "path_nor = 'test_normal.wav'\n",
    "text_output_nor = get_large_audio_transcription(path_nor)\n",
    "print(\"\\nNormal test text:\", text_output_nor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860d9426",
   "metadata": {},
   "source": [
    "## Save the text into Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f76cbf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the text to excel\n",
    "wb = xlwt.Workbook()\n",
    "ws = wb.add_sheet('A Test Sheet')\n",
    "ws.write(0, 0, text_output_dem)\n",
    "\n",
    "ws.write(1, 0, text_output_nor)\n",
    "wb.save('test_text.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3817e2c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
